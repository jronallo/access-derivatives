#!/usr/bin/env ruby

# Script that queries Sal for all Technician newspapers and
# creates OCR for each page and then combined resources for
# each resource.

require 'fileutils'
require 'tempfile'
require 'iiif_url'
require 'httpclient'
require 'json'

lock_file_name = '/tmp/process_technician_ocr.lock'
IiifUrl.set_base_url("https://iiif-prod01.lib.ncsu.edu/iiif")

# If the lock file does not exist we create it.
unless File.exist?(lock_file_name)
  FileUtils.touch(lock_file_name)
end

# Unless we get a lock on the lockfile we exit immediately.
# We keep a file handle open so that we retain the lock the whole time.
flock_file = File.open(lock_file_name, 'w')
unless flock_file.flock(File::LOCK_NB|File::LOCK_EX)
  puts "Can't get lock so exiting! No OCR processed."
  exit
end

# set up some paths
@ocr_directory = "/access-images/ocr/"
@http_client = HTTPClient.new

# Make the request to Sal for the results for the page
def get_technician_results_for_page(page: 1)
  url = "http://d.lib.ncsu.edu/collections/catalog.json?f[ispartof_facet][]=Technician&per_page=10&page=#{page}"
  response = @http_client.get url
  json = response.body
  JSON.parse json
end

# Based on a identifier determine if all the OCR files already exist
def ocr_already_exists?(identifier)
  base_filename = File.join directory_for_identifier(identifier), identifier
  File.size?(base_filename + '.txt') && File.size?(base_filename + '.hocr') && File.size?(base_filename + '.pdf')
end

def directory_for_identifier(identifier)
  first_two_of_identifier = identifier.slice(0, 2)
  File.join @ocr_directory, first_two_of_identifier, identifier
end

def create_word_boundary_json(identifier)
  json_filename = File.join directory_for_identifier(identifier), identifier + '.json'
  
end

# Given a doc iterate over each of the jp2s and process OCR for them
def process_ocr_for_each_page(doc)
  doc['jp2_filenames_sms'].each do |identifier|
    puts identifier

    # TODO: allow turning this feature off via CLI
    if ocr_already_exists?(identifier)
      puts "OCR already exists. Skipping #{identifier}"
      next
    end

    # create tempfile for image
    tmp_png = Tempfile.new([identifier, '.png'])
    # IIIF URL
    url = IiifUrl.from_params identifier: identifier, format: 'png'
    # get image with httpclient
    response = @http_client.get url
    # write image to tempfile
    tmp_png.puts response.body
    # create directory to put tesseract outputs
    tesseract_output_directory = directory_for_identifier(identifier)
    FileUtils.mkdir_p tesseract_output_directory
    # chanage to directory to put tesseract outputs
    Dir.chdir tesseract_output_directory
    # create outputs (txt, hOCR, PDF) with tesseract.
    # Look under /usr/share/tesseract/tessdata/configs/ to see hocr and pdf values.
    `tesseract #{tmp_png.path} #{identifier} -l eng hocr pdf`
    # remove the temporary file
    tmp_png.close
    tmp_png.unlink

    # TODO: Do a check that the files were properly created and if not remove them
    # if !ocr_already_exists?(identifier)

    # TODO: extract words and boundaries from hOCR into a JSON file
    hocr_filepath = File.join tesseract_output_directory, identifier + '.hocr'
    create_word_boundary_json(identifier)

  end
end

# Given a doc
def concatenate_ocr_for_resource(doc)
  # TODO: concatenate txt
  # TODO: concatenate PDFs
  # TODO: concatenate hOCR
end

# get the first page of results to find total_pages
response = get_technician_results_for_page
total_pages = response['response']['pages']['total_pages']

# Yes, there's a duplicate request for the first page here, but this is a bit
# simpler.
total_pages.times do |page|
  response = get_technician_results_for_page(page: page)
  response['response']['docs'].each do |doc|
    # A doc is a resource and can have multiple pages
    process_ocr_for_each_page(doc)
    concatenate_ocr_for_resource(doc)
    exit
  end
end


















flock_file.flock(File::LOCK_UN)
